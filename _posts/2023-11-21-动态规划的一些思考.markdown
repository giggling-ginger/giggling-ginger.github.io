---
layout: post
title: "动态规划的一些思考"
date: 2023-11-21 12:16:48 -0800
categories: jekyll update
---

最近看了些 Neetcode 又挑了点左和代码随想录的 dp 看，有了一些新的思考。

dp 是记忆化的递归，经典的斐波那契数列尤其好从 recursion 推到 dp。但更复杂一些的 dp，牵强地和我说递归推 dp、却又不给我具体证明过程的，这很难评。

dp 的状态转移方程，可以习惯了 dp 的思路，直接写；也可以从递归公式出发推。dp 数组的边界和初始化，也可以从递归的边界条件去推。

dp 比记忆化递归更好的地方在于，还可以用滚动数组进行空间上的优化。拿到背包题，牵强地写了半天递归，抠了半天代码；dp 数组长什么样却没感觉（记忆化用 set 就行了），更别说用滚动数组优化了。如果觉得 dp 实在难想，先把递归树画出来，递归公式和边界条件想一下，甚至一些参数也对 dp 数组的理解有帮助。

结论就是还是老实学 dp 好。

- 12.6 update

https://github.com/youngyangyang04/leetcode-master/blob/master/problems/%E8%83%8C%E5%8C%85%E6%80%BB%E7%BB%93%E7%AF%87.md

觉得 carl 对背包的分类与总结还是写得挺好挺细致挺容易理解的。在此基础上再自己总结下：

1. 遍历顺序
   1. 一般是先物品再背包，这样放在背包哪个顺序不会重复统计.
      除了排列相反，因为排列需要统计背包的不同顺序，也就是需要重复统计。
   2. 01 滚动内层循环需要倒着来，不能重复选择物品。多重则顺序，需要重复选择。
2. dp[j - weight[i]] + value[i] 背下来，做题直接滚动数组；当然不同题目的公式细节不一样。

看了一点 mit 算法导论关于 dp 的课，经典的 fib 推导和我想的一样。
而到底用记忆化回溯（发现有的题目只能这样做——可能也可以 dp 但是俺没学过，竞赛部分 skim through 就好，懒得 dive deep 了），还是 dp，看情况。
但要习惯 dp 这种思维方式。
